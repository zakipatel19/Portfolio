{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ee1e5-ef95-4c4b-b856-d6da5c8832f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d9c2e-7ca0-426b-9c78-cf591d5c54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count() \n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454c347-0d12-4165-8cf0-3ee955a32d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605574f-8e71-4e20-a116-a4002e4e2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)  # deprecated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac2e70-6689-4e18-80b1-2be9d75a40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# Replace the last layer with a new fully connected layer with the required number of output classes\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b169e5-c7ef-4f9e-8b4d-50204e0e5249",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "model= nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325638d-c959-4d8e-bcd6-0785b4460edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = zipfile.ZipFile('/scratch/mmpate15/pe_classification/data/train/train.zip')\n",
    "csv_file = zip_file.open('train.csv')\n",
    "\n",
    "df = pd.read_csv(csv_file, index_col =False)\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974d1de-2b37-4102-9f46-c90f088dc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folder_names = sorted( os.listdir('/scratch/mmpate15/pe_classification/data/train/train'))\n",
    "\n",
    "print(len(all_folder_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13807ce-9e5f-401c-b9ba-c33bd8170801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001f245-e2f9-4308-826b-3cf8643d2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_study_ids, test_study_ids = train_test_split(all_folder_names, train_size=350, test_size=100, shuffle=True, random_state=42)\n",
    "\n",
    "# Print the number of folders in each set\n",
    "print(f'Number of folders in training set: {len(train_study_ids)}')\n",
    "print(f'Number of folders in testing set: {len(test_study_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f1925-883b-4108-a036-7b17a027e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows that match the specified StudyID values for training data\n",
    "mask = df['StudyInstanceUID'].isin(train_study_ids)\n",
    "train_filtered_df = df[mask]\n",
    "train_filtered_df = train_filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36066977-5655-46fb-b573-2134bbe37f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = train_filtered_df.iloc[:, :4]\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9512cf-2837-4045-af81-e35a5d0d7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = X_df[\"pe_present_on_image\"].value_counts()\n",
    "print('inital class counts: \\n', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ba8e3-ab49-4e31-a4e6-d738ef1cd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = int(class_counts[1] + (class_counts[1]*0.65))\n",
    "max_count_0 = min(numb, class_counts[0]) # Set a limit of 500 for class 0\n",
    "max_count_1 = class_counts[1]  \n",
    "\n",
    "train_df_filtered = pd.concat([X_df[X_df[\"pe_present_on_image\"]==0][:max_count_0], X_df[X_df[\"pe_present_on_image\"]==1][:max_count_1]])\n",
    "train_df_filtered = train_df_filtered.reset_index(drop=True)\n",
    "train_df_filtered = train_df_filtered.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "(train_df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd04259-5d60-4877-8e46-d5e08aa94efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## balanced dataframe class count\n",
    "\n",
    "class_counts = train_df_filtered[\"pe_present_on_image\"].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2196f-4490-4794-9f5b-25a9e205fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = X_df[\"pe_present_on_image\"].value_counts()\n",
    "print('inital class counts: \\n', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59928726-256e-4516-8a03-f8ae3893da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows that match the specified StudyID values for testing data\n",
    "test_mask = df['StudyInstanceUID'].isin(test_study_ids)\n",
    "test_filtered_df = df[test_mask]\n",
    "test_filtered_df = test_filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df9cad-160e-4e1b-be3c-c04f25dcff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = test_filtered_df.iloc[:, :4]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0716a7c-475e-4b08-8737-cc4f79727da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y_df[\"pe_present_on_image\"].value_counts()\n",
    "print('inital class counts: \\n', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b42bae-6cad-46cf-8e8f-c24a1b28e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb =0\n",
    "class_count = 0\n",
    "max_count_0 = 0\n",
    "max_count_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530bc5c-6d2a-43f0-ac40-58998e62a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = int(class_counts[1] + (class_counts[1]*0.65))\n",
    "max_count_0 = min(numb, class_counts[0]) # Set a limit of 500 for class 0\n",
    "max_count_1 = class_counts[1]  \n",
    "\n",
    "test_df_filtered = pd.concat([y_df[y_df[\"pe_present_on_image\"]==0][:max_count_0], y_df[y_df[\"pe_present_on_image\"]==1][:max_count_1]])\n",
    "# test_df_filtered = test_df_filtered.reset_index(drop=True)\n",
    "test_df_filtered = test_df_filtered.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "(test_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6f29e-9cd9-427f-be09-ab84321ee9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = test_df_filtered[\"pe_present_on_image\"].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c70a4-12d6-4622-9671-3d4c3f16646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/scratch/mmpate15/pe_classification/data/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9662649-a26c-43a5-9197-43b7a2f4843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    classes = [0, 1]\n",
    "\n",
    "    def __init__(self, root_dir, df, transform):\n",
    "        self.data = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['StudyInstanceUID'], self.data.iloc[idx]['SeriesInstanceUID'],\n",
    "                                self.data.iloc[idx]['SOPInstanceUID'] + '.dcm').replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        \n",
    "        dcm = pydicom.read_file(img_path).pixel_array\n",
    "        img = Image.fromarray(np.uint8(dcm * 255), 'L')\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # img = transforms.ToTensor()(img)\n",
    "\n",
    "\n",
    "\n",
    "        label = torch.tensor(int(self.data['pe_present_on_image'][idx]))\n",
    "        \n",
    "        return img, label, img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93018f33-73fa-484a-a808-dc7409c22b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(224),\n",
    "                   T.ToTensor(),\n",
    "                   T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01729438-8c33-455e-84a3-eb982ba4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the DataSet\n",
    "\n",
    "train_dataset = MyDataset(root_dir, train_df_filtered, transform)\n",
    "test_dataset = MyDataset(root_dir, test_df_filtered, transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda43ba-0258-466b-9ca9-48f26eb894f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "class_counts = train_df_filtered['pe_present_on_image'].value_counts()\n",
    "\n",
    "# Create a countplot to visualize the class distribution\n",
    "sns.countplot(x='pe_present_on_image', data=train_df_filtered)\n",
    "plt.title('Training Set Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7f21a-b41d-441c-85b8-c41ebcf40436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844db82-024b-42ab-9e79-e390734c4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# Define the class weights\n",
    "# class_weights = torch.tensor([1.0, 30.0])\n",
    "# class_weights = class_weights.to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "# weight=class_weights\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506b947-517f-40a5-9dd9-ce1cc7502a01",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Creating the training loop\n",
    "\n",
    "f1_list = []\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "START = time.time()\n",
    "print(START)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    num_samples = 0.0    \n",
    "    conf_matrix = [[0, 0], [0, 0]]\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels, _ = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # outputs = outputs.to(device)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "         # Update statistics\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        num_samples += inputs.size(0)\n",
    "        \n",
    "        # Update the confusion matrix\n",
    "        conf_matrix += confusion_matrix(labels.cpu(), preds.cpu(), labels=[0, 1])\n",
    "\n",
    "        # print('\\n[%d, %5d] loss: %.3f, accuracy: %.3f' % (epoch + 1, i + 1, running_loss / num_samples, running_corrects / num_samples))\n",
    "        \n",
    "        # Collect predictions and true labels for f1 score calculation\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset)\n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_acc_list.append(epoch_acc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    print('\\nTrain Set: Epoch [%d/%d], Loss: %.4f, Accuracy: %.4f, F1: %.4f' % (epoch+1, num_epochs, epoch_loss, epoch_acc, f1))\n",
    "\n",
    "print('Finished Training & saved the model')\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet50_model_large.pth\")\n",
    "print(\"\\nModel saved to model.pth\")\n",
    "\n",
    "End = time.time()\n",
    "print(End)\n",
    "\n",
    "print(\"\\n Here is the testing confusion matrix: \\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30944125-7036-4a10-a29c-0acd86e17e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c587f4-ffcb-472e-846c-736af84b0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Calcualte the ROC curve and AUC score\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_pred[:])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, lw=1, alpha=1, label='ROC (AUC = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='gray', alpha=.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f7053-6ada-4a43-9c88-0d6b4fe150c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume train_acc_list is a list of CUDA tensors\n",
    "train_acc_list = train_acc_list\n",
    "\n",
    "# move tensors to CPU and convert to NumPy arrays\n",
    "train_acc_array = [t.cpu().numpy() for t in train_acc_list]\n",
    "\n",
    "# stack NumPy arrays into a single 2D array\n",
    "train_acc_array = np.stack(train_acc_array)\n",
    "\n",
    "print(train_acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7352a8-22c2-4c32-a59d-0da1dfae9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 16)  # assuming you trained for 15 epochs\n",
    "plt.plot(epochs, train_loss_list, label='Train Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559c84c-0c4c-4399-9bc0-8c0046082158",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = [0.7797, 0.9441, 0.9781, 0.9867, 0.9907, 0.9874, 0.9911, 0.9913, 0.9940, 0.9853, 0.9968, 0.9911, 0.9956, 0.9971, 0.9953]\n",
    "epochs = range(1, len(accuracy_list) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy_list, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481d8e2-c917-430b-8929-e9423271eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [0.7792, 0.8618, 0.9006, 0.9221, 0.9358, 0.9444, 0.9511, 0.9561, 0.9603, 0.9628, 0.9659, 0.9680, 0.9701, 0.9721, 0.9736]\n",
    "epochs = range(1, 16)\n",
    "\n",
    "plt.plot(epochs, f1_scores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22fc38-1ae6-4c46-8b28-3fdbe5ca0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "results = []\n",
    "y_true_test=[]\n",
    "y_pred_test=[]\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0.0\n",
    "    total = 0.0    \n",
    "    conf_matrix = [[0, 0], [0, 0]]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, img_names) in enumerate(test_loader):\n",
    "            # Forward pass\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Update loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Update accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Collect predictions and true labels for f1 score calculation\n",
    "            y_true_test.extend(targets.cpu().numpy())\n",
    "            y_pred_test.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            for i in range(len(predicted)):\n",
    "                # print(\"Image: {}, Prediction: {},\".format(img_names[i],predicted[i].item()))\n",
    "\n",
    "                results.append((img_names[i], predicted[i].item()))\n",
    "                \n",
    "            # Update the confusion matrix\n",
    "            conf_matrix += confusion_matrix(targets.cpu(), predicted.cpu(), labels=[0, 1])\n",
    "\n",
    "\n",
    "            total += targets.size(0)\n",
    "            test_correct += (predicted == targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = test_correct / len(test_dataset)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}')\n",
    "    \n",
    "print(\"\\nFinished Testing the model\")\n",
    "    \n",
    "print(\"\\n Here is the testing confusion matrix: \\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfab675-f1d6-4ebd-835b-3bb069e0fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f71998-cfb1-4e6c-a285-28643cfae47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.array(y_pred_test)\n",
    "y_true_test = np.array(y_true_test)\n",
    "\n",
    "# Calcualte the ROC curve and AUC score\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_pred[:])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"ROC AUC score: \", roc_auc)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, lw=1, alpha=1, label='ROC (AUC = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='gray', alpha=.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
